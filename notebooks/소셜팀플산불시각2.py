# -*- coding: utf-8 -*-
"""ì†Œì…œíŒ€í”Œì‚°ë¶ˆì‹œê°.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CA6thbdnAhSHSEgOQj7MZRMqu4XR6ywI
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!apt-get install -y fonts-nanum*
!rm -rf /root/.cache/matplotlib/* # í°íŠ¸ ìºì‹œ ì¬ì„¤ì •
# ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘ í›„ ì‹¤í–‰
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib as mpl
#
path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
font_name = mpl.font_manager.FontProperties(fname=path).get_name()
plt.rcParams['font.family'] = font_name

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import matplotlib.font_manager as fm
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
import geopandas as gpd
from shapely.geometry import Point

df = pd.read_csv("/content/ì‚°ë¦¼ì²­_ì‚°ë¶ˆìƒí™©ê´€ì œì‹œìŠ¤í…œ ì‚°ë¶ˆí†µê³„ë°ì´í„°_20241016.csv",encoding="cp949")


df['ë°œìƒì¼ì‹œ_ì „ì²´'] = pd.to_datetime(
    df['ë°œìƒì¼ì‹œ_ë…„'].astype(str) + '-' +
    df['ë°œìƒì¼ì‹œ_ì›”'].astype(str).str.zfill(2) + '-' +
    df['ë°œìƒì¼ì‹œ_ì¼'].astype(str).str.zfill(2) + ' ' +
    df['ë°œìƒì¼ì‹œ_ì‹œê°„']
)

df['ì§„í™”ì¢…ë£Œì¼ì‹œ_ì „ì²´'] = pd.to_datetime(
    df['ì§„í™”ì¢…ë£Œì‹œê°„_ë…„'].astype(str) + '-' +
    df['ì§„í™”ì¢…ë£Œì‹œê°„_ì›”'].astype(str).str.zfill(2) + '-' +
    df['ì§„í™”ì¢…ë£Œì‹œê°„_ì¼'].astype(str).str.zfill(2) + ' ' +
    df['ì§„í™”ì¢…ë£Œì‹œê°„_ì‹œê°„']
)


# timedelta (ì†Œìš” ì‹œê°„)
df['ì§„í™”_ì†Œìš”ì‹œê°„'] = (df['ì§„í™”ì¢…ë£Œì¼ì‹œ_ì „ì²´'] - df['ë°œìƒì¼ì‹œ_ì „ì²´'])
df['ì§„í™”_ì†Œìš”ì‹œê°„_ë¶„'] = df['ì§„í™”_ì†Œìš”ì‹œê°„'].dt.total_seconds() / 60
df['ë°œìƒì‹œê°„ëŒ€']=df['ë°œìƒì¼ì‹œ_ì‹œê°„'].str.split(':').str[0].astype(int)
#df.drop(columns=['ë°œìƒì¼ì‹œ_ë…„','ë°œìƒì¼ì‹œ_ì›”','ë°œìƒì¼ì‹œ_ì¼','ë°œìƒì¼ì‹œ_ì‹œê°„','ì§„í™”ì¢…ë£Œì‹œê°„_ë…„', 'ì§„í™”ì¢…ë£Œì‹œê°„_ì›”','ì§„í™”ì¢…ë£Œì‹œê°„_ì¼'], inplace=True)
df.head()

month_counts = df['ë°œìƒì¼ì‹œ_ì›”'].value_counts().sort_index()
month_counts.plot(kind='bar', color='skyblue')
plt.title('ì›”ë³„ ì‚°ë¶ˆ ë°œìƒ ê±´ìˆ˜')
plt.xlabel('ì›”')
plt.ylabel('ê±´ìˆ˜')
plt.xticks(rotation=0)
plt.show()

weekday_order = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
weekday_counts = df['ë°œìƒì¼ì‹œ_ìš”ì¼'].value_counts().reindex(weekday_order)
weekday_counts.plot(kind='bar', color='salmon')
plt.title('ìš”ì¼ë³„ ì‚°ë¶ˆ ë°œìƒ ë¹ˆë„')
plt.xlabel('ìš”ì¼')
plt.ylabel('ê±´ìˆ˜')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.hist(df['ë°œìƒì‹œê°„ëŒ€'], bins=24, color='skyblue', edgecolor='black')
plt.title('ì‹œê°„ëŒ€ë³„ ì‚°ë¶ˆ ë°œìƒ ë¹ˆë„')
plt.xlabel('ì‹œê°„ (0~23)')
plt.ylabel('ë°œìƒ ê±´ìˆ˜')
plt.xticks(range(24))
plt.grid(axis='y', alpha=0.75)
plt.show()

region_counts = df['ë°œìƒì¥ì†Œ_ì‹œë„'].value_counts()
region_counts.plot(kind='barh', color='teal')
plt.title('ì‹œë„ë³„ ì‚°ë¶ˆ ë°œìƒ')
plt.xlabel('ê±´ìˆ˜')
plt.ylabel('ì‹œë„')
plt.show()

df['ë°œìƒì›ì¸_êµ¬ë¶„'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)
plt.title('ì‚°ë¶ˆ ë°œìƒì›ì¸ êµ¬ë¶„ ë¹„ìœ¨')
plt.ylabel('')  # íŒŒì´ì°¨íŠ¸ì—ì„œ yì¶• ì œê±°
plt.show()

!apt-get -qq install fonts-nanum > /dev/null # Install the Nanum font package which includes Malgun Gothic
!fc-cache -fv > /dev/null # Clear and rebuild the font cache

import matplotlib.font_manager as fm
from wordcloud import WordCloud # Make sure you have this import
import matplotlib.pyplot as plt

font_path = fm.findfont('NanumGothic')  # Find the path to NanumGothic font

# Assuming 'ë°œìƒì›ì¸_ê¸°íƒ€' column contains the text data for the word cloud
text_data = ' '.join(df['ë°œìƒì›ì¸_ê¸°íƒ€'].astype(str).tolist()) # extract text data from 'ë°œìƒì›ì¸_ê¸°íƒ€' column

# Now use the font_path and text_data in WordCloud:
wordcloud = WordCloud(font_path=font_path, background_color='white', width=800, height=400).generate(text_data)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('ê¸°íƒ€ ë°œìƒì›ì¸ ì›Œë“œí´ë¼ìš°ë“œ')
plt.show()

cause_area = df.groupby('ë°œìƒì›ì¸_êµ¬ë¶„')['í”¼í•´ë©´ì _í•©ê³„'].sum().sort_values()
cause_area.plot(kind='barh', color='purple')
plt.title('ë°œìƒì›ì¸ë³„ í”¼í•´ë©´ì  í•©ê³„')
plt.xlabel('í”¼í•´ë©´ì  (ha)')
plt.show()

df['ì£¼ì†Œ'] = (
    df['ë°œìƒì¥ì†Œ_ì‹œë„'].fillna('') + ' ' +
    df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'].fillna('') + ' ' +
    df['ë°œìƒì¥ì†Œ_ìë©´'].fillna('') + ' ' +
    df['ë°œìƒì¥ì†Œ_ë™ë¦¬'].fillna('')
).str.split().str.join(' ')
df

gdf_sig = gpd.read_file("./sig.shp",encoding='euc-kr')
gdf_sig
unique_regions = gdf_sig['SIG_KOR_NM'].unique()
print(unique_regions)
print(df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'].unique())

# Step 1: Clean up region names in df

# Step 2: Standardize regions by creating a mapping dictionary

name_mapping = {

    'ê³ ì–‘': 'ê³ ì–‘ì‹œ',#and 'ê³ ì–‘ì‹œ ë•ì–‘êµ¬'and'ê³ ì–‘ì‹œ ì¼ì‚°ë™êµ¬'and'ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬',
    #'ê¸ˆë‚¨': 'ê¸ˆë‚¨êµ°', shpì— ê¸ˆë‚¨ì€ ì—†ìŒ
    'ì„±ë‚¨': 'ì„±ë‚¨ì‹œ',#and'ì„±ë‚¨ì‹œ ìˆ˜ì •êµ¬'and'ì„±ë‚¨ì‹œ ì¤‘ì›êµ¬' and'ì„±ë‚¨ì‹œ ë¶„ë‹¹',
    'ì•ˆì‚° ìƒë¡': 'ì•ˆì‚°ì‹œ ìƒë¡êµ¬',
    'ì•ˆì‚°' : 'ì•ˆì‚°ì‹œ ë‹¨ì›êµ¬',
    'ì•ˆì–‘': 'ì•ˆì–‘ì‹œ',#and'ì•ˆì–‘ì‹œ ë§Œì•ˆêµ¬'and'ì•ˆì–‘ì‹œ ë™ì•ˆêµ¬',
    #'ì—°ë™': 'ì—°ë™ì‹œ',  shpì— ì—°ë™ì—†ìŒ
    'ìš©ì¸ ì²˜ì¸': 'ìš©ì¸ì‹œ ì²˜ì¸êµ¬',
    'ìš©ì¸' : 'ìš©ì¸ì‹œ ê¸°í¥êµ¬',# and 'ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬',
    'ì „ì˜': 'ì „ì£¼ì‹œ ì „ì˜ë©´', #shpì— ì—†ìŒ
    'ì „ì£¼ ì™„ì‚°': 'ì „ì£¼ì‹œ ì™„ì‚°êµ¬',
    'ì „ì£¼' : 'ì „ì£¼ì‹œ ë•ì§„êµ¬',
    'ì§„í•´': 'ì°½ì›ì‹œ ì§„í•´êµ¬',
    'ì°½ì› ë§ˆì‚°í•©í¬': 'ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬',
    'ì°½ì› ì˜ì°½' : 'ì°½ì›ì‹œ ì˜ì°½êµ¬',
    'ì°½ì› ë§ˆì‚°íšŒì›' : 'ì°½ì›ì‹œ ë§ˆì‚°íšŒì›êµ¬',
    'ì°½ì› ' : 'ì°½ì›ì‹œ ì„±ì‚°êµ¬',
    'ì²œì•ˆ ë™ë‚¨': 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',
    'ì²œì•ˆ ì„œë¶': 'ì²œì•ˆì‹œ ì„œë¶êµ¬',
    'ì²œì•ˆ' : 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',#and'ì²œì•ˆì‹œ ì„œë¶êµ¬',
    'í¬í•­ ë‚¨': 'í¬í•­ì‹œ ë‚¨êµ¬',
    'í¬í•­ ë¶': 'í¬í•­ì‹œ ë¶êµ¬',
    'í¬í•­' : 'í¬í•­ì‹œ ë‚¨êµ¬' #and 'í¬í•­ì‹œ ë¶êµ¬'
}

df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'] = df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'].replace(name_mapping)

# Step 3: Clean region names in gdf_sig similarly (ì •ì œëŠ” shapefile ìª½ë§Œ)
gdf_sig['SIG_KOR_NM'] = gdf_sig['SIG_KOR_NM'].str.replace(r"ì‹œ|êµ¬|êµ°", "", regex=True).str.strip()

# Step 4: Also remove ì‹œ/êµ°/êµ¬ from df AFTER mapping (if really needed)
df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'] = df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'].str.replace(r"ì‹œ|êµ¬|êµ°", "", regex=True).str.strip()
# Step 4: Merge the datasets
merged = gdf_sig.merge(df, left_on='SIG_KOR_NM', right_on='ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬', how='left')

# Step 5: Create the 'incident_count' column
merged['incident_count'] = merged.groupby('SIG_KOR_NM')['ë°œìƒì¼ì‹œ_ì¼'].transform('count')

# Step 6: Plot the heatmap
fig, ax = plt.subplots(figsize=(12, 12))
merged.plot(column='incident_count', cmap='YlOrRd', ax=ax,
            edgecolor='black', linewidth=0.5, legend=True,
            vmin=0, vmax=merged['incident_count'].max())
# Step 7: Debugging - Checking for missing regions in the shapefile
df_sgg = df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬'].fillna('').str.strip().unique()
shp_sgg = gdf_sig['SIG_KOR_NM'].fillna('').str.strip().unique()

# Convert to sets to eliminate duplicates
df_sgg_set = set(df_sgg)
shp_sgg_set = set(shp_sgg)

# Find regions present in df but not in gdf_sig
missing_in_shp = df_sgg_set - shp_sgg_set
print("âŒ [DF â†’ SHP] dfì—ëŠ” ìˆì§€ë§Œ shpì— ì—†ëŠ” ì‹œêµ°êµ¬:")
for sgg in sorted(missing_in_shp):
    print("  -", sgg)

#ë™êµ¬ ë‚¨êµ¬ ê°™ì€ê³³ì´ ì¤‘ë³µë˜ëŠ” í˜„ìƒë°œìƒ *********************************************

# ì‹œêµ°êµ¬ë³„ í™”ì¬ ë°œìƒ ê±´ìˆ˜ ì§‘ê³„
top30 = (
    df['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']
    .value_counts()
    .reset_index()
    .rename(columns={'index': 'ì‹œêµ°êµ¬', 'ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬': 'í™”ì¬ê±´ìˆ˜'})
    .head(30)
)

# ì¶œë ¥
print("ğŸ”¥ ì‹œêµ°êµ¬ë³„ í™”ì¬ ë°œìƒ Top 30:")
print(top30.to_string(index=False))


### ë¶ê³¼ ê°™ì€ ì´ìƒí•œ ìƒí™© ë°œìƒ ã… 
df

import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
import geopandas as gpd
from shapely.geometry import Point
# ì§€ì˜¤ì½”ë” ì´ˆê¸°í™” ë° ì†ë„ ì œí•œ
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# tqdm ì ìš©
tqdm.pandas()

# ì§€ì˜¤ì½”ë”©
print("ğŸ“ ì§€ì˜¤ì½”ë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
df['location'] = df['ì£¼ì†Œ'].progress_apply(geocode)

# ìœ„ë„/ê²½ë„ ë¶„ë¦¬
df['ìœ„ë„'] = df['location'].apply(lambda loc: loc.latitude if loc else None)
df['ê²½ë„'] = df['location'].apply(lambda loc: loc.longitude if loc else None)

# ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ í•­ëª© ì¶œë ¥
failed = df[df['ìœ„ë„'].isna()]
if not failed.empty:
    print(f"â— ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ê±´ìˆ˜: {len(failed)}")
    print("ì‹¤íŒ¨í•œ ì£¼ì†Œ ì˜ˆì‹œ:")
    print(failed[['ì£¼ì†Œ']].head())

# ìœ íš¨ ì¢Œí‘œë§Œ í•„í„°ë§
df_valid = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])

# GeoDataFrame ìƒì„±
# ìœ íš¨ ì¢Œí‘œë§Œ í•„í„°ë§
df_valid = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])

gdf = gpd.GeoDataFrame(df_valid, geometry=gpd.points_from_xy(df_valid['ê²½ë„'], df_valid['ìœ„ë„']))
gdf.set_crs(epsg=4326, inplace=True)

# ê²°ê³¼ ì €ì¥
df.to_csv("./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì „ì²´ê²°ê³¼.csv", index=False, encoding='utf-8-sig')
print("âœ… ì „ì²´ ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì „ì²´ê²°ê³¼.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

df_success = df[df['ìœ„ë„'].notna()].copy()
df_fail = df[df['ìœ„ë„'].isna()].copy()

# ìƒ˜í”Œë¡œ 5ê°œì”© ì¶œë ¥í•´ ë³´ê¸°
print("âœ… ì§€ì˜¤ì½”ë”© ì„±ê³µ ì£¼ì†Œ ì˜ˆì‹œ:")
print(df_success['ì£¼ì†Œ'].head())

print("\nâŒ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ì£¼ì†Œ ì˜ˆì‹œ:")
print(df_fail['ì£¼ì†Œ'].head())

import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì „ì²´ê²°ê³¼.csv", encoding="utf-8-sig")

# 2. ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨í•œ í–‰ë§Œ ë¶„ë¦¬
df_fail = df[df['ìœ„ë„'].isna()].copy()
df_success = df[df['ìœ„ë„'].notna()].copy()
print(f"â— ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ê±´ìˆ˜: {len(df_fail)}")

# 3. ì£¼ì†Œ ë³´ì • í•¨ìˆ˜ ì •ì˜
def build_full_address(row):
    parts = []

    # ì‹œë„
    ì‹œë„ = row.get('ë°œìƒì¥ì†Œ_ì‹œë„')
    if pd.notna(ì‹œë„):
        parts.append(ì‹œë„)

    # ì‹œêµ°êµ¬
    ì‹œêµ°êµ¬ = row.get('ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬')
    if pd.notna(ì‹œêµ°êµ¬):
        if not ì‹œêµ°êµ¬.endswith(('ì‹œ', 'êµ°', 'êµ¬')):
            ì‹œêµ°êµ¬ += 'ì‹œ'  # ê¸°ë³¸ê°’ì€ ì‹œ
        parts.append(ì‹œêµ°êµ¬)

    # ìë©´
    ìë©´ = row.get('ë°œìƒì¥ì†Œ_ìë©´')
    if pd.notna(ìë©´):
        if not ìë©´.endswith(('ì', 'ë©´', 'ë™')):
            ìë©´ += 'ë©´'  # ëŒ€ë¶€ë¶„ ë©´ìœ¼ë¡œ ê°€ì •
        parts.append(ìë©´)

    # ë™ë¦¬
    ë™ë¦¬ = row.get('ë°œìƒì¥ì†Œ_ë™ë¦¬')
    if pd.notna(ë™ë¦¬):
        if not ë™ë¦¬.endswith(('ë¦¬', 'ë™')):
            ë™ë¦¬ += 'ë¦¬'
        parts.append(ë™ë¦¬)

    return ' '.join(parts)

# 4. ì£¼ì†Œ ë³´ì •
df_fail['ì£¼ì†Œ_ë³´ì •'] = df_fail.apply(build_full_address, axis=1)
# 5. ì§€ì˜¤ì½”ë”© ì¤€ë¹„
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 6. ë³´ì • ì£¼ì†Œë¡œ ì§€ì˜¤ì½”ë”© ì¬ì‹œë„
print("ğŸ“ ë³´ì •ëœ ì£¼ì†Œë¡œ ì§€ì˜¤ì½”ë”© ì¬ì‹œì‘...")
df_fail['location'] = df_fail['ì£¼ì†Œ_ë³´ì •'].progress_apply(geocode)
df_fail['ìœ„ë„'] = df_fail['location'].apply(lambda loc: loc.latitude if loc else None)
df_fail['ê²½ë„'] = df_fail['location'].apply(lambda loc: loc.longitude if loc else None)

# 7. ì„±ê³µ ë°ì´í„° + ì¬ì‹œë„ ì„±ê³µ ë°ì´í„° ë³‘í•©
df_final = pd.concat([df_success, df_fail], ignore_index=True)

# 8. ê²°ê³¼ ì €ì¥
df_final.to_csv("./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ë³´ì •ê²°ê³¼.csv", index=False, encoding='utf-8-sig')
print("âœ… ìµœì¢… ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ë³´ì •ê²°ê³¼.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

df_retry

"""
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. ë³´ì •ëœ ì£¼ì†Œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ë³´ì •ê²°ê³¼.csv", encoding="utf-8-sig")

# 2. ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ + ë³´ì •ì£¼ì†Œ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
df_retry = df[(df['ì£¼ì†Œ_ë³´ì •'].notna()) & (df['ìœ„ë„'].isna())].copy()
print(f"ğŸ“Œ ì¬ë³´ì • ëŒ€ìƒ ê±´ìˆ˜: {len(df_retry)}")

# 3. ëŒ€í•œë¯¼êµ­ ë¶™ì´ê¸° (ì£¼ì†Œ ì¸ì‹ë¥  í–¥ìƒ)
df_retry.loc[:, 'ì£¼ì†Œ_ë³´ì •_ìµœì¢…'] = df_retry['ì£¼ì†Œ_ë³´ì •'].astype(str) + ' ëŒ€í•œë¯¼êµ­'

# 4. Nominatim ì„¤ì •
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 5. ì¬ì§€ì˜¤ì½”ë”©
print("ğŸ“ ì¬ì§€ì˜¤ì½”ë”© ì¤‘...")
df_retry['location'] = df_retry['ì£¼ì†Œ_ë³´ì •_ìµœì¢…'].progress_apply(geocode)
df_retry['ìœ„ë„'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['ê²½ë„'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)

# 6. ì›ë³¸ì—ì„œ ì¬ì‹œë„ ëŒ€ìƒ ì œê±° í›„ ë³‘í•©
df_keep = df[~df.index.isin(df_retry.index)]
df_final = pd.concat([df_keep, df_retry], ignore_index=True)

# 7. ì €ì¥
df_final.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("âœ… ì¬ë³´ì • ë° ë³‘í•© ì™„ë£Œ â†’ 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…ê²°ê³¼.csv' ì €ì¥ë¨")
"""

"""
!pip install geokakao

import pandas as pd
import geokakao as gk
from tqdm import tqdm
import time
import requests

# âœ… ì¹´ì¹´ì˜¤ REST API í‚¤ ì…ë ¥ (ë°˜ë“œì‹œ ë³¸ì¸ í‚¤ë¡œ êµì²´)
KAKAO_API_KEY = "bb589f5598d656483016cc22a3fb3e22"

# CSV ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…ê²°ê³¼.csv', encoding='utf-8-sig')

# ì£¼ì†Œ ì ‘ë¯¸ì‚¬ ë¶™ì´ëŠ” í•¨ìˆ˜ ì •ì˜
def suffix_addr(row):
    sido = str(row['ë°œìƒì¥ì†Œ_ì‹œë„']).strip()
    sigungu = str(row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']).strip()
    eupmyeon = str(row['ë°œìƒì¥ì†Œ_ìë©´']).strip()
    dongri = str(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']).strip()

    if eupmyeon and not eupmyeon.endswith(('ë©´', 'ë™', 'ë¦¬')):
        eupmyeon += 'ë™'
    if dongri and not dongri.endswith(('ë©´', 'ë™', 'ë¦¬')):
        dongri += 'ë¦¬'

    parts = [sido, sigungu, eupmyeon, dongri]
    parts = [p for p in parts if p and p.lower() != 'nan']
    return ' '.join(parts)

# ì ‘ë¯¸ì‚¬ ë¶™ì¸ ì£¼ì†Œ ì»¬ëŸ¼ ìƒì„±
df['ì£¼ì†Œ_ì ‘ë¯¸ì‚¬'] = df.apply(suffix_addr, axis=1)

# ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ì£¼ì†Œë§Œ ì¶”ì¶œ (ê¸°ì¡´ 'ìœ„ë„'ê°€ NaNì´ë©´ì„œ, ì£¼ì†Œ_ì ‘ë¯¸ì‚¬ ìˆëŠ” í–‰)
df_retry = df[df['ìœ„ë„'].isna() & df['ì£¼ì†Œ_ì ‘ë¯¸ì‚¬'].notna()].copy()
print(f"ğŸ“ ì¹´ì¹´ì˜¤ ì¬ì‹œë„ ëŒ€ìƒ: {len(df_retry)}ê±´")

# ìœ„ë„/ê²½ë„ ì´ˆê¸°í™”
df_retry['ìœ„ë„'] = None
df_retry['ê²½ë„'] = None

# 1ì°¨: geokakaoë¡œ ì¬ì‹œë„
for idx, row in tqdm(df_retry.iterrows(), total=len(df_retry)):
    try:
        single_df = pd.DataFrame([row])
        result_df = gk.add_coordinates_to_dataframe(single_df, 'ì£¼ì†Œ_ì ‘ë¯¸ì‚¬')
        if result_df is not None and not result_df.empty:
            lat = result_df.at[0, 'ìœ„ë„'] if 'ìœ„ë„' in result_df.columns else None
            lng = result_df.at[0, 'ê²½ë„'] if 'ê²½ë„' in result_df.columns else None
            if lat and lng:
                df_retry.at[idx, 'ìœ„ë„'] = lat
                df_retry.at[idx, 'ê²½ë„'] = lng
            else:
                print(f"â— ì‹¤íŒ¨(ì¢Œí‘œ ì—†ìŒ): {row['ì£¼ì†Œ_ì ‘ë¯¸ì‚¬']}")
        else:
            print(f"â— ì‹¤íŒ¨(ë¹ˆ ê²°ê³¼): {row['ì£¼ì†Œ_ì ‘ë¯¸ì‚¬']}")
    except Exception as e:
        print(f"â— ì‹¤íŒ¨(ì—ëŸ¬): {row['ì£¼ì†Œ_ì ‘ë¯¸ì‚¬']} â†’ {e}")
    time.sleep(0.3)

# 2ì°¨: ë‹¨ê³„ë³„ ì£¼ì†Œ ê°„ëµí™” ì¬ì‹œë„ í•¨ìˆ˜
def get_kakao_coord(address, api_key):
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {api_key}"}
    params = {"query": address}
    resp = requests.get(url, headers=headers, params=params)
    if resp.status_code == 200:
        documents = resp.json().get('documents')
        if documents:
            x = documents[0].get('x')
            y = documents[0].get('y')
            return float(y), float(x)
    return None, None

def try_address_variants(row, api_key):
    sido = row['ë°œìƒì¥ì†Œ_ì‹œë„']
    sigungu = row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']
    eupmyeon = row['ë°œìƒì¥ì†Œ_ìë©´']
    dongri = row['ë°œìƒì¥ì†Œ_ë™ë¦¬']

    if eupmyeon and not eupmyeon.endswith(('ë©´','ë™','ë¦¬')):
        eupmyeon += 'ë™'
    if dongri and not dongri.endswith(('ë©´','ë™','ë¦¬')):
        dongri += 'ë¦¬'

    address_list = [
        f"{sido} {sigungu} {eupmyeon} {dongri}".strip(),
        f"{sido} {sigungu} {eupmyeon}".strip(),
        f"{sido} {sigungu}".strip(),
        f"{sido}".strip()
    ]

    for addr in address_list:
        lat, lng = get_kakao_coord(addr, api_key)
        if lat and lng:
            return lat, lng
    return None, None

# geokakao 1ì°¨ ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•œ ë°ì´í„° ëŒ€ìƒìœ¼ë¡œ 2ì°¨ ì¬ì‹œë„
df_retry2 = df_retry[df_retry['ìœ„ë„'].isna() | df_retry['ê²½ë„'].isna()].copy()

for idx, row in tqdm(df_retry2.iterrows(), total=len(df_retry2)):
    lat, lng = try_address_variants(row, KAKAO_API_KEY)
    if lat and lng:
        df_retry.at[idx, 'ìœ„ë„'] = lat
        df_retry.at[idx, 'ê²½ë„'] = lng
    else:
        print(f"â— ì‹¤íŒ¨(ë¹ˆ ê²°ê³¼): {row['ë°œìƒì¥ì†Œ_ì‹œë„']} {row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']} {row['ë°œìƒì¥ì†Œ_ìë©´']} {row['ë°œìƒì¥ì†Œ_ë™ë¦¬']}")
    time.sleep(0.3)

# ê¸°ì¡´ ì¢Œí‘œ ì˜ ë‚˜ì˜¨ ë°ì´í„° + ì¬ì‹œë„ ê²°ê³¼ ë³‘í•©
df_final = pd.concat([df[~df.index.isin(df_retry.index)], df_retry], ignore_index=True)

# ì €ì¥
df_final.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì¹´ì¹´ì˜¤ë³´ì •_ìµœì¢…ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("âœ… ì¹´ì¹´ì˜¤ ë³´ì • ì™„ë£Œ â†’ 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì¹´ì¹´ì˜¤ë³´ì •_ìµœì¢…ê²°ê³¼.csv'")

import pandas as pd
import geopandas as gpd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
"""
# -----------------------------
# ğŸ“Œ ì‹œêµ°êµ¬ ë³´ì • ë”•ì…”ë„ˆë¦¬
# -----------------------------
sgg_mapping = {

    'ê³ ì–‘': 'ê³ ì–‘ì‹œ',#and 'ê³ ì–‘ì‹œ ë•ì–‘êµ¬'and'ê³ ì–‘ì‹œ ì¼ì‚°ë™êµ¬'and'ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬',
    #'ê¸ˆë‚¨': 'ê¸ˆë‚¨êµ°', shpì— ê¸ˆë‚¨ì€ ì—†ìŒ
    'ì„±ë‚¨': 'ì„±ë‚¨ì‹œ',#and'ì„±ë‚¨ì‹œ ìˆ˜ì •êµ¬'and'ì„±ë‚¨ì‹œ ì¤‘ì›êµ¬' and'ì„±ë‚¨ì‹œ ë¶„ë‹¹',
    'ì•ˆì‚° ìƒë¡': 'ì•ˆì‚°ì‹œ ìƒë¡êµ¬',
    'ì•ˆì‚°' : 'ì•ˆì‚°ì‹œ ë‹¨ì›êµ¬',
    'ì•ˆì–‘': 'ì•ˆì–‘ì‹œ',#and'ì•ˆì–‘ì‹œ ë§Œì•ˆêµ¬'and'ì•ˆì–‘ì‹œ ë™ì•ˆêµ¬',
    #'ì—°ë™': 'ì—°ë™ì‹œ',  shpì— ì—°ë™ì—†ìŒ
    'ìš©ì¸ ì²˜ì¸': 'ìš©ì¸ì‹œ ì²˜ì¸êµ¬',
    'ìš©ì¸' : 'ìš©ì¸ì‹œ ê¸°í¥êµ¬',# and 'ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬',
    'ì „ì˜': 'ì „ì£¼ì‹œ ì „ì˜ë©´', #shpì— ì—†ìŒ
    'ì „ì£¼ ì™„ì‚°': 'ì „ì£¼ì‹œ ì™„ì‚°êµ¬',
    'ì „ì£¼' : 'ì „ì£¼ì‹œ ë•ì§„êµ¬',
    'ì§„í•´': 'ì°½ì›ì‹œ ì§„í•´êµ¬',
    'ì°½ì› ë§ˆì‚°í•©í¬': 'ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬',
    'ì°½ì› ì˜ì°½' : 'ì°½ì›ì‹œ ì˜ì°½êµ¬',
    'ì°½ì› ë§ˆì‚°íšŒì›' : 'ì°½ì›ì‹œ ë§ˆì‚°íšŒì›êµ¬',
    'ì°½ì› ' : 'ì°½ì›ì‹œ ì„±ì‚°êµ¬',
    'ì²œì•ˆ ë™ë‚¨': 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',
    'ì²œì•ˆ ì„œë¶': 'ì²œì•ˆì‹œ ì„œë¶êµ¬',
    'ì²œì•ˆ' : 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',#and'ì²œì•ˆì‹œ ì„œë¶êµ¬',
    'í¬í•­ ë‚¨': 'í¬í•­ì‹œ ë‚¨êµ¬',
    'í¬í•­ ë¶': 'í¬í•­ì‹œ ë¶êµ¬',
    'í¬í•­' : 'í¬í•­ì‹œ ë‚¨êµ¬' #and 'í¬í•­ì‹œ ë¶êµ¬'
}
def generate_address(row):
    sido = str(row['ë°œìƒì¥ì†Œ_ì‹œë„']).strip()
    sgg = str(row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']).strip()
    eupmyeon = str(row['ë°œìƒì¥ì†Œ_ìë©´']) if pd.notnull(row['ë°œìƒì¥ì†Œ_ìë©´']) else ''
    dongri = str(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) if pd.notnull(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) else ''

    full_sgg = sgg_mapping.get(sgg, sgg)
    address = f"{sido} {full_sgg} {eupmyeon} {dongri}".strip()
    return address

# 3. CSV ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…ê²°ê³¼.csv', encoding='utf-8-sig')

# 4. ì‹œêµ°êµ¬ ë³´ì • í›„ ì£¼ì†Œ ì¬ìƒì„±
df['ì£¼ì†Œ'] = df.apply(generate_address, axis=1)

# 5. ì§€ì˜¤ì½”ë” ì´ˆê¸°í™” ë° RateLimiter ì„¤ì •
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# 6. ìœ„ë„/ê²½ë„ ì—†ëŠ” í–‰ë§Œ í•„í„°ë§í•´ì„œ ì¬ì‹œë„
df_retry = df[df['ìœ„ë„'].isna()].copy()

tqdm.pandas()
df_retry['location'] = df_retry['ì£¼ì†Œ'].progress_apply(geocode)

# 7. ì¢Œí‘œ ë‹¤ì‹œ ì±„ìš°ê¸°
df_retry['ìœ„ë„'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['ê²½ë„'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)

# 8. ê¸°ì¡´ df ì— ì¬ì‹œë„ ê²°ê³¼ ë³‘í•©
df.update(df_retry[['ìœ„ë„', 'ê²½ë„']])

# 9. ì¢Œí‘œ ì—†ëŠ” í–‰ í™•ì¸ (í•„ìš”ì‹œ ë¡œê·¸ ì¶œë ¥ ë° íŒŒì¼ ì €ì¥)
missing = df[df['ìœ„ë„'].isna()]
print(f"ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ì£¼ì†Œ ìˆ˜: {len(missing)}")
if len(missing) > 0:
    print("â—ï¸ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨í•œ ì£¼ì†Œ ëª©ë¡:")
    for addr in missing['ì£¼ì†Œ']:
        print(f" - {addr}")
# 10. GeoDataFrame ìƒì„± (í•„ìš” ì‹œ)
gdf = gpd.GeoDataFrame(df.dropna(subset=['ìœ„ë„', 'ê²½ë„']), geometry=gpd.points_from_xy(df['ê²½ë„'], df['ìœ„ë„']))
gdf.set_crs(epsg=4326, inplace=True)

# 11. ìµœì¢… ê²°ê³¼ ì €ì¥
df.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("âœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv'")
"""

#----------------------------------------------------------------

"""
# -----------------------------
# ğŸ“Œ ì£¼ì†Œ ìƒì„± í•¨ìˆ˜
# -----------------------------
def generate_address(row):
    sido = str(row['ë°œìƒì¥ì†Œ_ì‹œë„']).strip()
    sgg = str(row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']).strip()
    eupmyeon = str(row['ë°œìƒì¥ì†Œ_ìë©´']) if pd.notnull(row['ë°œìƒì¥ì†Œ_ìë©´']) else ''
    dongri = str(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) if pd.notnull(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) else ''

    # ì‹œêµ°êµ¬ ë§¤í•‘
    full_sgg = sgg_mapping.get(sgg, sgg)
    address = f"{sido} {full_sgg} {eupmyeon} {dongri}".strip()
    return address

# -----------------------------
# ğŸ“Œ ì§€ì˜¤ì½”ë”© ì „ì²´ ì²˜ë¦¬ í•¨ìˆ˜
# -----------------------------

# ì§€ì˜¤ì½”ë” ì´ˆê¸°í™”
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# tqdmìœ¼ë¡œ ì§„í–‰ í‘œì‹œ
tqdm.pandas()
df['location'] = df['ì£¼ì†Œ'].progress_apply(geocode)

# ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ ë¶„ë¦¬
df['ìœ„ë„'] = df['location'].apply(lambda loc: loc.latitude if loc else None)
df['ê²½ë„'] = df['location'].apply(lambda loc: loc.longitude if loc else None)

# ìœ íš¨ ì¢Œí‘œë§Œ í•„í„°ë§
df = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])

# GeoDataFrame ìƒì„±
gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['ê²½ë„'], df['ìœ„ë„']))
gdf.set_crs(epsg=4326, inplace=True)
# ì§€ì˜¤ì½”ë”© ê²°ê³¼ ì €ì¥

df.to_csv("./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ê²°ê³¼.csv", index=False, encoding='utf-8-sig')
print("âœ… ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ê²°ê³¼.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""
import pandas as pd
import geopandas as gpd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# -----------------------------
# ğŸ“Œ ì‹œêµ°êµ¬ ë³´ì • ë”•ì…”ë„ˆë¦¬
# -----------------------------
"""
sgg_mapping = {
    'ê³ ì–‘': 'ê³ ì–‘ì‹œ',
    'ì„±ë‚¨': 'ì„±ë‚¨ì‹œ',
    'ì•ˆì‚° ìƒë¡': 'ì•ˆì‚°ì‹œ ìƒë¡êµ¬',
    'ì•ˆì‚°': 'ì•ˆì‚°ì‹œ ë‹¨ì›êµ¬',
    'ì•ˆì–‘': 'ì•ˆì–‘ì‹œ',
    'ìš©ì¸ ì²˜ì¸': 'ìš©ì¸ì‹œ ì²˜ì¸êµ¬',
    'ìš©ì¸': 'ìš©ì¸ì‹œ ê¸°í¥êµ¬',
    'ì „ì£¼ ì™„ì‚°': 'ì „ì£¼ì‹œ ì™„ì‚°êµ¬',
    'ì „ì£¼': 'ì „ì£¼ì‹œ ë•ì§„êµ¬',
    'ì§„í•´': 'ì°½ì›ì‹œ ì§„í•´êµ¬',
    'ì°½ì› ë§ˆì‚°í•©í¬': 'ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬',
    'ì°½ì› ë§ˆì‚°íšŒì›': 'ì°½ì›ì‹œ ë§ˆì‚°íšŒì›êµ¬',
    'ì°½ì› ì˜ì°½': 'ì°½ì›ì‹œ ì˜ì°½êµ¬',
    'ì°½ì›': 'ì°½ì›ì‹œ ì„±ì‚°êµ¬',
    'ì²œì•ˆ ë™ë‚¨': 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',
    'ì²œì•ˆ ì„œë¶': 'ì²œì•ˆì‹œ ì„œë¶êµ¬',
    'ì²œì•ˆ': 'ì²œì•ˆì‹œ ë™ë‚¨êµ¬',
    'í¬í•­ ë‚¨': 'í¬í•­ì‹œ ë‚¨êµ¬',
    'í¬í•­ ë¶': 'í¬í•­ì‹œ ë¶êµ¬',
    'í¬í•­': 'í¬í•­ì‹œ ë‚¨êµ¬'
}
"""
# -----------------------------
# ğŸ“Œ ì£¼ì†Œ ìƒì„± í•¨ìˆ˜
# -----------------------------
def generate_address(row):
    sido = str(row['ë°œìƒì¥ì†Œ_ì‹œë„']).strip()
    sgg = str(row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']).strip()
    eupmyeon = str(row['ë°œìƒì¥ì†Œ_ìë©´']).strip() if pd.notnull(row['ë°œìƒì¥ì†Œ_ìë©´']) else ''
    dongri = str(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']).strip() if pd.notnull(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) else ''

    # ìë©´ì´ ì—†ê³  ë™ë¦¬ë§Œ ìˆì„ ë•Œ â†’ ë™ë¦¬ë¥¼ ìë©´ìœ¼ë¡œ ì‚¬ìš©
    if eupmyeon == '' and dongri != '':
        eupmyeon = dongri
        dongri = ''

    # ìë©´ ì ‘ë¯¸ì‚¬ ë¶™ì´ê¸°
    if eupmyeon and not eupmyeon.endswith(('ì', 'ë©´', 'ë™')):
        eupmyeon += 'ë©´'  # ê¸°ë³¸ê°’ìœ¼ë¡œ 'ë©´' ë¶™ì´ê¸°

    # full_sggê°€ ëˆ„ë½ë˜ì–´ì„œ ë³€ìˆ˜ ì—ëŸ¬ ë‚©ë‹ˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨íˆ sggë§Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    return f"{sido} {sgg} {eupmyeon}".strip()  # ë™ë¦¬ëŠ” ì œì™¸

# -----------------------------
# ğŸ“Œ ì§€ì˜¤ì½”ë”© ì‹œë„ í•¨ìˆ˜ (ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥)
# -----------------------------
def try_geocode(addr):
    try:
        loc = geocode(addr)
        if loc is None:
            print(f"âŒ ì‹¤íŒ¨: {addr}")
        else:
            print(f"âœ… ì„±ê³µ: {addr} â†’ {loc.address}")  # ì „ì²´ ì£¼ì†Œ ì¶œë ¥ ì¶”ê°€
        return loc
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜: {addr} | {e}")
        return None

# 1. CSV ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…ê²°ê³¼.csv', encoding='utf-8-sig')

# 2. ì£¼ì†Œ ìƒì„±
df['ì£¼ì†Œ'] = df.apply(generate_address, axis=1)

# 3. ì§€ì˜¤ì½”ë” ì´ˆê¸°í™” ë° RateLimiter ì„¤ì •
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# 4. ìœ„ë„/ê²½ë„ ì—†ëŠ” í–‰ë§Œ í•„í„°ë§
df_retry = df[df['ìœ„ë„'].isna()].copy()

# 5. ì§€ì˜¤ì½”ë”© ìˆ˜í–‰ (ì‹¤ì‹œê°„ ì½˜ì†” ë¡œê·¸ í¬í•¨)
tqdm.pandas()
df_retry['location'] = df_retry['ì£¼ì†Œ'].progress_apply(try_geocode)

# 6. ì¢Œí‘œ ë° ì „ì²´ ì£¼ì†Œ ì±„ìš°ê¸°
df_retry['ìœ„ë„'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['ê²½ë„'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)
df_retry['location'] = df_retry['location'].apply(lambda loc: loc.address if loc else None)
# 7. ì›ë³¸ dfì— ì—…ë°ì´íŠ¸
df.update(df_retry[['ìœ„ë„', 'ê²½ë„', 'location']])

# 8. ì‹¤íŒ¨ ì£¼ì†Œ ìµœì¢… ì¶œë ¥
missing = df[df['ìœ„ë„'].isna()]
print(f"\nğŸš¨ ìµœì¢… ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ ì£¼ì†Œ ìˆ˜: {len(missing)}")
if len(missing) > 0:
    print("ğŸ“ ì‹¤íŒ¨í•œ ì£¼ì†Œ ëª©ë¡:")
    for addr in missing['ì£¼ì†Œ']:
        print(f" - {addr}")

# 9. GeoDataFrame ìƒì„± (ì„ íƒ ì‚¬í•­)
try:
    gdf = gpd.GeoDataFrame(df.dropna(subset=['ìœ„ë„', 'ê²½ë„']), geometry=gpd.points_from_xy(df['ê²½ë„'], df['ìœ„ë„']))
    gdf.set_crs(epsg=4326, inplace=True)
except Exception as e:
    print(f"âš ï¸ GeoDataFrame ìƒì„± ì˜¤ë¥˜: {e}")

# 10. ê²°ê³¼ ì €ì¥
df.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("\nâœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv'")

#ì§€ì˜¤ì½”ë”©ìœ¼ë¡œ ì™„ë²½í•œ ì£¼ì†Œ ë„£ê¸°


from geopy.extra.rate_limiter import RateLimiter

# ë¦¬ë²„ìŠ¤ ì§€ì˜¤ì½”ë” ì´ˆê¸°í™”
reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)

# 1. ìœ„ë„/ê²½ë„ëŠ” ìˆìœ¼ë‚˜ locationì´ ë¹„ì–´ ìˆëŠ” ê²½ìš°
df_reverse = df[(df['ìœ„ë„'].notna()) & (df['ê²½ë„'].notna()) & (df['location'].isna())].copy()

# 2. ë¦¬ë²„ìŠ¤ ì§€ì˜¤ì½”ë”© í•¨ìˆ˜
def try_reverse_geocode(lat, lon):
    try:
        loc = reverse((lat, lon))
        if loc is None:
            print(f"âŒ ë¦¬ë²„ìŠ¤ ì‹¤íŒ¨: {lat}, {lon}")
        else:
            print(f"âœ… ë¦¬ë²„ìŠ¤ ì„±ê³µ: {lat}, {lon} â†’ {loc.address}")
        return loc.address if loc else None
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜: {lat}, {lon} | {e}")
        return None

# 3. location ì±„ìš°ê¸°
tqdm.pandas()
df_reverse['location'] = df_reverse.progress_apply(lambda row: try_reverse_geocode(row['ìœ„ë„'], row['ê²½ë„']), axis=1)

# 4. ì›ë³¸ df ì—…ë°ì´íŠ¸
df.update(df_reverse[['location']])

df.drop(columns=['ì£¼ì†Œ_ë³´ì •', 'ì£¼ì†Œ_ë³´ì •_ìµœì¢…'], inplace=True, errors='ignore')

df.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ì™„ì „ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("\nâœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv'")

"""
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. ì´ì „ ê²°ê³¼ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ê²°ê³¼.csv', encoding='utf-8-sig')

# 2. ìœ„ë„/ê²½ë„ ì—†ëŠ” í–‰ë§Œ ì¶”ì¶œ
df_retry = df[df['ìœ„ë„'].isna()].copy()

def generate_full_address(row):
    sido = str(row['ë°œìƒì¥ì†Œ_ì‹œë„']).strip()
    sgg = str(row['ë°œìƒì¥ì†Œ_ì‹œêµ°êµ¬']).strip()
    dongri = str(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']).strip() if pd.notnull(row['ë°œìƒì¥ì†Œ_ë™ë¦¬']) else ''

    # ì‹œêµ°êµ¬ê°€ ë¹„ì–´ìˆì§€ ì•Šê³ , "êµ¬"ê°€ ì—†ìœ¼ë©´ "êµ¬" ë¶™ì„
    if sgg and not sgg.endswith('êµ¬'):
        sgg += 'êµ¬'

    # ë™ë¦¬ê°€ ë¹„ì–´ìˆì§€ ì•Šê³ , "ë™"ì´ ì—†ìœ¼ë©´ "ë™" ë¶™ì„
    if dongri and not dongri.endswith('ë™'):
        dongri += 'ë™'

    # ìë©´ì€ ë¬´ì‹œí•˜ê³ , ì£¼ì†Œ í•©ì¹˜ê¸° (ë„ì–´ì“°ê¸° ì£¼ì˜)
    address = f"{sido} {sgg} {dongri}".strip()
    return address

# ì ìš© ì˜ˆì‹œ
df['ì£¼ì†Œ'] = df.apply(generate_full_address, axis=1)
# 4. ì§€ì˜¤ì½”ë”© ì¤€ë¹„
geolocator = Nominatim(user_agent="fire-mapper-ri")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 5. ì§€ì˜¤ì½”ë”© ì‹œë„
def try_geocode(address):
    location = geocode(address)
    if location:
        print(f"âœ… ì„±ê³µ: {address}")
    else:
        print(f"âŒ ì‹¤íŒ¨: {address}")
    return location

df_retry['ìœ„ë„'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['ê²½ë„'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)
df_retry['location'] = df_retry['location'].apply(lambda loc: loc.address if loc else None)

# 7. ì›ë³¸ dfì— ì—…ë°ì´íŠ¸
df.update(df_retry[['ìœ„ë„', 'ê²½ë„', 'location']])

# 7. ë‹¤ì‹œ ì €ì¥
df.to_csv('./ì‚°ë¶ˆ_ì§€ì˜¤ì½”ë”©_ìµœì¢…_ì¬ë³´ì •_ìµœì¢…_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
print("âœ… 'ì' ë¶™ì—¬ì„œ ì¬ì‹œë„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

"""

pip install geopandas pandas folium matplotlib shapely

df_filtered = df.dropna(subset=['ìœ„ë„', 'ê²½ë„']).copy() # Filter first and create a copy
gdf_points = gpd.GeoDataFrame(
    df_filtered, # Use the filtered DataFrame for data
    geometry=gpd.points_from_xy(df_filtered['ê²½ë„'], df_filtered['ìœ„ë„']) # Use the filtered DataFrame for geometry
)
gdf_points.set_crs(epsg=4326, inplace=True)
gdf_points
gdf=gdf_points

import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
from shapely.geometry import Point

# 1. ëŒ€í•œë¯¼êµ­ ì‹œêµ°êµ¬ shp íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
shp_path = '/content/sig.shp'  # ì‹œêµ°êµ¬ ê²½ê³„íŒŒì¼ ê²½ë¡œ
gdf_admin = gpd.read_file(shp_path,encoding='euc-kr')


# 2. ìœ„ê²½ë„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. ì‹œêµ°êµ¬ Shapefile ì¢Œí‘œê³„ ì„¤ì • ë° ë³€í™˜
gdf_admin.set_crs(epsg=5179, inplace=True)
gdf_admin = gdf_admin.to_crs(epsg=4326)  # WGS84ë¡œ ë§ì¶¤

# 4. Spatial Join
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 5. ì‹œêµ°êµ¬ë³„ íˆíŠ¸ë§µ ì§‘ê³„
heatmap = joined.groupby('SIG_KOR_NM').size().reset_index(name='count')
gdf_admin_heatmap = gdf_admin.merge(heatmap, on='SIG_KOR_NM', how='left')
gdf_admin_heatmap['count'] = gdf_admin_heatmap['count'].fillna(0)

# 6. ì‹œê°í™”
fig, ax = plt.subplots(1, 1, figsize=(12, 14))
gdf_admin_heatmap.plot(column='count', ax=ax, legend=True, cmap='OrRd', edgecolor='gray')
plt.title('ì‹œêµ°êµ¬ë³„ ìœ„ì¹˜ ë°ì´í„° íˆíŠ¸ë§µ', fontsize=16)
plt.axis('off')
plt.tight_layout()
plt.show()

import folium
from folium.plugins import HeatMap
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
shp_path = '/content/sig.shp'
gdf_admin = gpd.read_file(shp_path, encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# 2. í¬ì¸íŠ¸ CSV ë¡œë“œ

geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Folium ì§€ë„ ìƒì„±
m = folium.Map(location=[36.5, 127.5], zoom_start=6, tiles='cartodbpositron')

# 4. í¬ì¸íŠ¸ íˆíŠ¸ë§µ ì¶”ê°€
heat_data = [[point.y, point.x] for point in gdf_points.geometry]
HeatMap(heat_data).add_to(m)

# í¬ì¸íŠ¸ë§ˆë‹¤ ë§ˆì»¤ ì¶”ê°€
for _, row in gdf.iterrows():
    tooltip = f"{row['ì£¼ì†Œ']}<br>í”¼í•´ë©´ì : {row['í”¼í•´ë©´ì _í•©ê³„']} ha"
    folium.CircleMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        radius=4,
        color='red',
        fill=True,
        fill_opacity=0.6,
        tooltip=tooltip
    ).add_to(m)

m.save('folium_markers.html')
m

import folium
from folium import Choropleth
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. ì‹œêµ°êµ¬ í–‰ì •ê²½ê³„ ë¡œë“œ ë° ì¢Œí‘œê³„ ì„¤ì •
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# 2. ìœ„ê²½ë„ ë°ì´í„° ë¡œë“œ ë° GeoDataFrame ìƒì„±
geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Spatial Join (ì–´ëŠ ì‹œêµ°êµ¬ì— ì†í•˜ëŠ”ì§€)
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì  í•©ê³„ ì§‘ê³„
damage_by_admin = joined.groupby('SIG_KOR_NM')['í”¼í•´ë©´ì _í•©ê³„'].sum().reset_index()
damage_by_admin.columns = ['SIG_KOR_NM', 'total_damage']

# 5. ì‹œêµ°êµ¬ GeoDataFrameê³¼ ë³‘í•©
gdf_admin = gdf_admin.merge(damage_by_admin, on='SIG_KOR_NM', how='left')
gdf_admin['total_damage'] = gdf_admin['total_damage'].fillna(0)

# 6. Folium ì§€ë„ ìƒì„±
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 7. ì‹œêµ°êµ¬ ê²½ê³„ ìƒ‰ìƒ ì…íˆê¸° (Choropleth)
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', 'total_damage'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì  (ha)'
).add_to(m)

# 8. íˆ´íŒ ë° ê²½ê³„ì„ ì— íŒì—… ì¶”ê°€
for _, row in gdf_admin.iterrows():
    tooltip = f"{row['SIG_KOR_NM']}<br>í”¼í•´ë©´ì : {row['total_damage']} ha"
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {
            'fillColor': '#ffffff00',
            'color': 'black',
            'weight': 0.5,
            'fillOpacity': 0
        },
        tooltip=tooltip
    ).add_to(m)

# 9. ì €ì¥
m.save('folium_admin_colormap.html')
m

#ìš¸ì§„êµ°ì´ ë„ˆë¬´ ë§ì´ë‚˜ì™€ì„œ ë¹¼ê³ í•˜ëŠ” ì½”ë“œ
import folium
from folium import Choropleth
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. ì‹œêµ°êµ¬ í–‰ì •ê²½ê³„ ë¡œë“œ ë° ì¢Œí‘œê³„ ì„¤ì •
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# âœ… ìš¸ì§„êµ° ì œì™¸ ********************************************
gdf_admin = gdf_admin[gdf_admin['SIG_KOR_NM'] != 'ìš¸ì§„êµ°']

# 2. ìœ„ê²½ë„ ë°ì´í„° ë¡œë“œ ë° GeoDataFrame ìƒì„±
geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Spatial Join (ì–´ëŠ ì‹œêµ°êµ¬ì— ì†í•˜ëŠ”ì§€)
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì  í•©ê³„ ì§‘ê³„
damage_by_admin = joined.groupby('SIG_KOR_NM')['í”¼í•´ë©´ì _í•©ê³„'].sum().reset_index()
damage_by_admin.columns = ['SIG_KOR_NM', 'total_damage']

# 5. ì‹œêµ°êµ¬ GeoDataFrameê³¼ ë³‘í•©
gdf_admin = gdf_admin.merge(damage_by_admin, on='SIG_KOR_NM', how='left')
gdf_admin['total_damage'] = gdf_admin['total_damage'].fillna(0)

# 6. Folium ì§€ë„ ìƒì„±
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 7. Choropleth ì¶”ê°€
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', 'total_damage'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì  (ha)'
).add_to(m)

# 8. íˆ´íŒ ì¶”ê°€
for _, row in gdf_admin.iterrows():
    tooltip = f"{row['SIG_KOR_NM']}<br>í”¼í•´ë©´ì : {row['total_damage']} ha"
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {
            'fillColor': '#ffffff00',
            'color': 'black',
            'weight': 0.5,
            'fillOpacity': 0
        },
        tooltip=tooltip
    ).add_to(m)

# 9. ì €ì¥
m.save('folium_admin_colormap_without_uljin.html')
m

# ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì  ì§‘ê³„ (í”¼í•´í•©ê³„ì™€ íšŸìˆ˜)
damage_stats = joined.groupby('SIG_KOR_NM').agg(
    í”¼í•´ë©´ì _í•©ê³„=('í”¼í•´ë©´ì _í•©ê³„', 'sum'),
    í”¼í•´_íšŸìˆ˜=('í”¼í•´ë©´ì _í•©ê³„', 'count')
).reset_index()

# ì •ë ¬ëœ í‘œ ë³´ê¸°
damage_stats_sorted = damage_stats.sort_values(by='í”¼í•´ë©´ì _í•©ê³„', ascending=False)

# ìƒìœ„ 10ê°œë§Œ ë¯¸ë¦¬ ë³´ê¸°
print(damage_stats_sorted.head(10))

import folium
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point
from folium.plugins import HeatMap

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

#*******************************************************************
gdf_admin = gdf_admin[gdf_admin['SIG_KOR_NM'] != 'ìš¸ì§„êµ°']


# 2. GeoDataFrame ë³€í™˜
geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')


# 3. ì‹œêµ°êµ¬ Spatial Join
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. ì‹œêµ°êµ¬ë³„ í”¼í•´ ì§‘ê³„
damage_stats = joined.groupby('SIG_KOR_NM').agg(
    í”¼í•´ë©´ì _í•©ê³„=('í”¼í•´ë©´ì _í•©ê³„', 'sum'),
    í”¼í•´_íšŸìˆ˜=('í”¼í•´ë©´ì _í•©ê³„', 'count')
).reset_index()
gdf_admin = gdf_admin.merge(damage_stats, on='SIG_KOR_NM', how='left')
gdf_admin[['í”¼í•´ë©´ì _í•©ê³„', 'í”¼í•´_íšŸìˆ˜']] = gdf_admin[['í”¼í•´ë©´ì _í•©ê³„', 'í”¼í•´_íšŸìˆ˜']].fillna(0)

# 5. ì§€ë„ ìƒì„±
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 6. Choropleth: ì‹œêµ°êµ¬ë³„ í”¼í•´ë©´ì 
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', 'í”¼í•´ë©´ì _í•©ê³„'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='ì‚°ë¶ˆ í”¼í•´ë©´ì  í•©ê³„ (ha)',
).add_to(m)

# 7. ì‹œêµ°êµ¬ íŒì—… ì¶”ê°€
for _, row in gdf_admin.iterrows():
    tooltip = (
        f"<b>{row['SIG_KOR_NM']}</b><br>"
        f"í”¼í•´ë©´ì : {row['í”¼í•´ë©´ì _í•©ê³„']:.2f} ha<br>"
        f"í”¼í•´ íšŸìˆ˜: {int(row['í”¼í•´_íšŸìˆ˜'])}íšŒ"
    )
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {'fillColor': '#00000000', 'color': 'black', 'weight': 0.4},
        tooltip=tooltip
    ).add_to(m)

# 8. íˆíŠ¸ë§µ ë ˆì´ì–´ ì¶”ê°€
heat_data = [[row['ìœ„ë„'], row['ê²½ë„']] for _, row in df.iterrows()]
HeatMap(heat_data, radius=10, blur=15, min_opacity=0.3).add_to(m)

# 9. ì‚°ë¶ˆ ìœ„ì¹˜ ë§ˆì»¤ ì¶”ê°€
for _, row in df.iterrows():
    tooltip = f"{row['ì£¼ì†Œ']}<br>í”¼í•´ë©´ì : {row['í”¼í•´ë©´ì _í•©ê³„']} ha"
    folium.CircleMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        radius=4,
        color='red',
        fill=True,
        fill_opacity=0.7,
        tooltip=tooltip
    ).add_to(m)

# 10. ì €ì¥
m.save('wildfire_map.html')

m



df.to_csv('./ì§€ì˜¤ì½”ë”©ì™„ì „ì²´.csv', index=False, encoding='utf-8-sig')
print("\nâœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì§€ì˜¤ì½”ë”©ì™„ì „ì²´.csv'")

df = pd.read_csv('./ì§€ì˜¤ì½”ë”©ì™„ì „ì²´.csv', encoding='utf-8-sig')
df

sig = gpd.read_file('/content/sig.shp', encoding='euc-kr')
sig

import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

sig = gpd.read_file('/content/sig.shp', encoding='euc-kr')
sig.set_crs(epsg=5179, inplace=True)
sig = sig.to_crs('EPSG:4326')

geometry = [Point(xy) for xy in zip(df['ê²½ë„'], df['ìœ„ë„'])]
gdf_points = gpd.GeoDataFrame(df.copy(), geometry=geometry, crs='EPSG:4326')

# 4. Spatial Join: ê° í¬ì¸íŠ¸ê°€ ì–´ëŠ ì‹œêµ°êµ¬ì— ì†í•˜ëŠ”ì§€
joined = gpd.sjoin(gdf_points, sig[['SIG_KOR_NM', 'SIG_CD', 'SIG_ENG_NM', 'geometry']],
                   how='left', predicate='within')

# 5. ê²°ê³¼ ì •ë¦¬ (í•„ìš”í•œ ì—´ë§Œ ë‚¨ê¸°ê¸°)
df_merged = joined.drop(columns='geometry')  # í¬ì¸íŠ¸ geometry ì œê±°

missing = joined[joined['SIG_KOR_NM'].isna()]
print(missing[['ìœ„ë„', 'ê²½ë„', 'location']])

# ë¶€ì‚° ê°•ì„œêµ¬ (ì¤‘ë³µ 3ê°œ)
for idx in [281, 285, 348]:
    joined.loc[idx, 'SIG_KOR_NM'] = 'ê°•ì„œêµ¬'
    joined.loc[idx, 'SIG_CD'] = '26440'
    joined.loc[idx, 'SIG_ENG_NM'] = 'Gangseo-gu'

# ê²½ë‚¨ ê±°ì œì‹œ (ì¤‘ë³µ 4ê°œ: 682, 733, 942, 1129)
for idx in [682, 733, 942, 1129]:
    joined.loc[idx, 'SIG_KOR_NM'] = 'ê±°ì œì‹œ'
    joined.loc[idx, 'SIG_CD'] = '48880'
    joined.loc[idx, 'SIG_ENG_NM'] = 'Geoje-si'

# ì „ë¶ ë¶€ì•ˆêµ° (1ê°œ)
joined.loc[983, 'SIG_KOR_NM'] = 'ë¶€ì•ˆêµ°'
joined.loc[983, 'SIG_CD'] = '45640'
joined.loc[983, 'SIG_ENG_NM'] = 'Buan-gun'

# ê²½ê¸° ì•ˆì‚°ì‹œ ë‹¨ì›êµ¬ (1ê°œ)
joined.loc[60, 'SIG_KOR_NM'] = 'ë‹¨ì›êµ¬'
joined.loc[60, 'SIG_CD'] = '41273'
joined.loc[60, 'SIG_ENG_NM'] = 'Danwon-gu'

df_merged = joined.drop(columns=['geometry', 'index_right'])

# í˜¹ì‹œ ëª¨ë¥¼ ëˆ„ë½ ë‹¤ì‹œ ì²´í¬
print(df_merged['SIG_KOR_NM'].isna().sum())  # 0ì´ì–´ì•¼ ì •ìƒ



df_merged.to_csv('./ì§€ì˜¤ì½”ë”©ë°ì‹œêµ°êµ¬ì½”ë“œ.csv', index=False, encoding='utf-8-sig')
print("\nâœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì§€ì˜¤ì½”ë”©ë°ì‹œêµ°êµ¬ì½”ë“œ.csv'")

df_merged = pd.read_csv('./ì§€ì˜¤ì½”ë”©ë°ì‹œêµ°êµ¬ì½”ë“œ.csv', encoding='utf-8-sig')

#í”¼í•´ë©´ì  ì‚°ë¶ˆíšŸìˆ˜ 2x2 top5ê°œ ë½‘ê¸°
#ê¸°ì¤€í•˜ë‚˜ ì •í•´ë³´ì
#ê°€ì •í•˜ê³ ë“¤ì–´ê°€ë©´ íšŸìˆ˜ê°€ ì¤‘ìš”í• ë“¯?
#ì¹¨ì—½ìˆ˜ê°€ ê°€ì§€ê³  ìˆëŠ” ë¹„ìœ¨ì´ ë§ì„ë•Œ í”¼í•´íšŸìˆ˜ê°€ ë§ë‹¤.
#íšŸìˆ˜ë„ ë¤ìœ¼ë¡œ í•˜ì

#ì¹¨ì—½ìˆ˜ ë¹„ìœ¨ ë§ì€ ì§€ì—­ì´ í”¼í•´ì •ë„ê°€ í°ê°€? """"
#ì¹¨ì—½ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë°œìƒíšŸìˆ˜ê°€ ë§ì€ê°€? """"
#>ì´í›„ë¡œ ë§ì€ ì§€ì—­ì°¾ì•„ì„œ í™”ì¬ë°œìƒ ê°€ëŠ¥ì„±ì´ ìˆë‹¤
#topëª‡ê°œë½‘ì•„ì„œ ê²°ë¡  ë„ì¶œ

#ì¹¨ì—½ìˆ˜ê°€ ë” ë¹„ì‹¸ë‹¤ //   ì‹¤ì§ˆì  ì´ìœ ì¡°ì‚¬í•˜ê¸°
#ì‚°ë¶ˆë°ì´í„° ë„ˆë¬´ ì ìŒ

#ì›ì¸ ì¹¨ì—½ìˆ˜ê°€ ì˜íƒ„ë‹¤ --


#ì‚°ë¶ˆ, í‰ê·  ë‹¤í•´ë³´ê³ 
#1. ìƒê´€ë¶„ì„ í”¼ì–´ìŠ¨ ---ìœ ì˜ë¯¸í•˜ë‹¤ê³  ë‚˜ì™€ì•¼í•¨
#ì‚°ë¦¼ë¹„ìœ¨   ì¢…ì†: ì‚°ë¶ˆíšŸìˆ˜, ë©´ì , í‰ê· 
#->> ë‹¤ìŒ í•´ë³´ê³ ì‹¶ì€ê±° ë‹¤í•´ë³´ê³ 

#í•œë‹¬ì— ëª‡ë²ˆ ì¼ì–´ë‚¬ë‚˜
#ì›”ë³„ ëª‡íšŒë„ ì¶”ê°€í•´ë¼

#sig_cdì´ê±¸ë¡œ ë§ì¶°ì„œ 'êµ¬' ë¡œ ê¹”ë”í•˜ê²Œ ë‚˜ì˜¤ê²Œ dfë§Œë“¤ì–´ê¸°

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# seaborn ìŠ¤íƒ€ì¼ ì„¤ì •
sns.set(style="whitegrid")
plt.rcParams['font.family'] = 'NanumGothic'  # í•œê¸€ í°íŠ¸ (Colabì—ì„œëŠ” 'NanumGothic')

# 1. í”¼í•´ë©´ì  ìƒìœ„ 30ê°œ ì‹œêµ°êµ¬
top_damage = df_merged.groupby('SIG_KOR_NM')['í”¼í•´ë©´ì _í•©ê³„'].sum().sort_values(ascending=False).head(30)
plt.figure(figsize=(12, 8))
sns.barplot(x=top_damage.values, y=top_damage.index, palette='Reds_r')
plt.title('í”¼í•´ë©´ì  ìƒìœ„ 30ê°œ ì‹œêµ°êµ¬ (ë‹¨ìœ„: ha)')
plt.xlabel('í”¼í•´ë©´ì  í•©ê³„ (ha)')
plt.ylabel('ì‹œêµ°êµ¬')
plt.tight_layout()
plt.show()

# 2. ì‚°ë¶ˆ íšŸìˆ˜ ìƒìœ„ 30ê°œ ì‹œêµ°êµ¬
top_counts = df_merged['SIG_KOR_NM'].value_counts().head(30)
plt.figure(figsize=(12, 8))
sns.barplot(x=top_counts.values, y=top_counts.index, palette='Blues_r')
plt.title('ì‚°ë¶ˆ ë°œìƒ íšŸìˆ˜ ìƒìœ„ 30ê°œ ì‹œêµ°êµ¬')
plt.xlabel('ì‚°ë¶ˆ ë°œìƒ íšŸìˆ˜')
plt.ylabel('ì‹œêµ°êµ¬')
plt.tight_layout()
plt.show()

# 3. ì›”ë³„ ì‚°ë¶ˆ ë°œìƒ íšŸìˆ˜
df_merged['ë°œìƒì¼ì‹œ_ì›”'] = pd.to_numeric(df_merged['ë°œìƒì¼ì‹œ_ì›”'], errors='coerce')  # í˜¹ì‹œ ë¬¸ìì—´ì´ë©´ ë³€í™˜
monthly_counts = df_merged['ë°œìƒì¼ì‹œ_ì›”'].value_counts().sort_index()
plt.figure(figsize=(10, 6))
sns.barplot(x=monthly_counts.index, y=monthly_counts.values, palette='Set3')
plt.title('ì›”ë³„ ì‚°ë¶ˆ ë°œìƒ íšŸìˆ˜')
plt.xlabel('ì›”')
plt.ylabel('ë°œìƒ íšŸìˆ˜')
plt.xticks(range(0, 12), labels=[f"{i+1}ì›”" for i in range(12)])
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'NanumGothic'
top_n = 5

# ì›”ë³„ ë£¨í”„
for month in range(1, 13):
    monthly_df = df_merged[df_merged['ë°œìƒì¼ì‹œ_ì›”'] == month]
    top_regions = (
        monthly_df.groupby('SIG_KOR_NM')
        .size()
        .sort_values(ascending=False)
        .head(top_n)
    )

    plt.figure(figsize=(10, 6))
    sns.barplot(x=top_regions.values, y=top_regions.index, palette="YlOrBr_r")
    plt.title(f'{month}ì›” ë°œìƒê±´ìˆ˜ ìƒìœ„ {top_n} ì‹œêµ°êµ¬')
    plt.xlabel('ë°œìƒ ê±´ìˆ˜')
    plt.ylabel('ì‹œêµ°êµ¬')
    plt.tight_layout()
    plt.show()

import pandas as pd

# ì˜ˆì‹œ: df_full ì´ ì „ì²´ ë°ì´í„°í”„ë ˆì„ì´ë¼ê³  ê°€ì •
columns_to_keep = [
    'SIG_KOR_NM','í”¼í•´ë©´ì _í•©ê³„','ë°œìƒì›ì¸_êµ¬ë¶„',
    'ë°œìƒì¼ì‹œ_ì „ì²´','ì§„í™”ì¢…ë£Œì¼ì‹œ_ì „ì²´','ì§„í™”_ì†Œìš”ì‹œê°„_ë¶„','ë°œìƒì¼ì‹œ_ìš”ì¼','ë°œìƒì‹œê°„ëŒ€',
    'ì§„í™”_ì†Œìš”ì‹œê°„_ë¶„',
]

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
df_cleaned = df_merged[columns_to_keep].copy()

# ê²°ì¸¡ê°’ í™•ì¸
print(df_cleaned.isnull().sum())

# ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
print(df_cleaned.head())

#ë”°ë¡œ ì €ì¥í•„ìš”í•˜ë©´
"""
df_cleaned.save_csv('./ì •ì œëœìµœì¢….csv', index=False, encoding='utf-8-sig')
print("\nâœ… ìµœì¢… ì¬ë³´ì • ê²°ê³¼ ì €ì¥ ì™„ë£Œ: 'ì •ì œëœìµœì¢….csv'")
"""